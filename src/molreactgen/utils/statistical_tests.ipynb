{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Prepare the statistical tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95a6405014065f5e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_1samp, ttest_ind  # t"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.277487599Z",
     "start_time": "2023-11-01T14:01:13.009272566Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ALTERNATIVES = (\"two-sided\", \"less\", \"greater\")\n",
    "ALPHA = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.317604598Z",
     "start_time": "2023-11-01T14:01:13.316575509Z"
    }
   },
   "id": "444ab0135c733968"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Sample:\n",
    "    values: Sequence[float]\n",
    "    array: np.ndarray = None\n",
    "    ddof: int = 1\n",
    "    mean: float = None\n",
    "    std: float = None\n",
    "    variance: float = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.array = np.array(self.values)\n",
    "        self.mean, self.std, self.var = self.get_basic_stats()\n",
    "\n",
    "    def get_basic_stats(self) -> tuple[float, float, float]:\n",
    "        mean = np.mean(self.array)\n",
    "        std = np.std(self.array, ddof=self.ddof)\n",
    "        var = np.var(self.array, ddof=self.ddof)\n",
    "        return mean, std, var\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.array)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Sample({self.values}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.array})\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.317820382Z",
     "start_time": "2023-11-01T14:01:13.316839793Z"
    }
   },
   "id": "2e1f4a4d72352cdf"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# This was/is only a test whether my two_sample_t_test function works (it does)\n",
    "def compare_two_samples(s1: Sample, s2: Sample) -> tuple[float, float]:\n",
    "    t_stat, p_value = ttest_ind(s1.array, s2.array)  # just to check; fake!\n",
    "    return t_stat, p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.317935776Z",
     "start_time": "2023-11-01T14:01:13.317046260Z"
    }
   },
   "id": "27019476b7749854"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Same calculation for both one and two sample t-tests\n",
    "def _calculate_p_value(t_statistic: float, df: int, alternative: str) -> float:\n",
    "    alternative = alternative.strip().lower()\n",
    "    if alternative == \"two_sided\":\n",
    "        p_value = (1 - t.cdf(abs(t_statistic), df)) * 2.0\n",
    "    elif alternative == \"less\":\n",
    "        p_value = t.cdf(t_statistic, df)\n",
    "    elif alternative == \"greater\":\n",
    "        p_value = 1 - t.cdf(t_statistic, df)\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be 'two_sided', 'greater' or 'smaller'\")\n",
    "\n",
    "    return p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.318035970Z",
     "start_time": "2023-11-01T14:01:13.317192873Z"
    }
   },
   "id": "68200c14b46ccc24"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def is_normally_distributed(sample: Sample, alpha: float = ALPHA):\n",
    "    _, p_value = shapiro(sample.array)\n",
    "    return p_value > alpha"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.326656642Z",
     "start_time": "2023-11-01T14:01:13.317414074Z"
    }
   },
   "id": "c0d4cdc77bbde306"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def one_sample_t_test(\n",
    "    sample: Sample, population_mean: float, alternative: str = \"two_sided\"\n",
    ") -> tuple[float, float]:\n",
    "    # n = len(sample)\n",
    "    # df = n - 1\n",
    "    # t_statistic = (sample.mean - population_mean) / (sample.std / np.sqrt(n))\n",
    "    # p_value = _calculate_p_value(t_statistic, df, alternative)\n",
    "\n",
    "    if not is_normally_distributed(sample):\n",
    "        print(\"Warning: sample is not normally distributed!\")\n",
    "        # print(\"Therefore, we do a Wilcoxon signed-rank test instead of a Student's t-test!\")\n",
    "        # test_statistic, p_value = wilcoxon(sample.array - population_mean, alternative=alternative)\n",
    "        # return test_statistic, p_value\n",
    "    test_statistic, p_value = ttest_1samp(\n",
    "        sample.array, population_mean, alternative=alternative\n",
    "    )\n",
    "    return test_statistic, p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.336825032Z",
     "start_time": "2023-11-01T14:01:13.327209847Z"
    }
   },
   "id": "d2ce292f1d0d6014"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def two_sample_t_test(\n",
    "    sample: Sample, baseline: Sample, alternative: str = \"different\"\n",
    ") -> tuple[float, float]:\n",
    "    # n1 = len(sample)\n",
    "    # n2 = len(baseline)\n",
    "    if sample.std > 2.0 * baseline.std or baseline.std > 2.0 * sample.std:\n",
    "        print(\"Warning: standard deviations differ by more than a factor of 2\")\n",
    "        print(\"Therefore, we do a Welch's t-test instead of a Student's t-test!\")\n",
    "        equal_var = False\n",
    "    else:\n",
    "        equal_var = True\n",
    "\n",
    "    # pooled_std = np.sqrt(((n1 - 1) * sample.std ** 2 + (n2 - 1) * baseline.std ** 2) / (n1 + n2 - 2))\n",
    "    # t_statistic = (sample.mean - baseline.mean) / (pooled_std * np.sqrt(1 / n1 + 1 / n2))\n",
    "    # df = n1 + n2 - 2\n",
    "    # p_value = _calculate_p_value(t_statistic, df, alternative)\n",
    "\n",
    "    if not is_normally_distributed(sample):\n",
    "        print(\"Warning: sample is not normally distributed!\")\n",
    "        # print(\"Therefore, we do a Wilcoxon signed-rank test instead of a Student's t-test!\")\n",
    "        # test_statistic, p_value = wilcoxon(sample.array - population_mean, alternative=alternative)\n",
    "        # return test_statistic, p_value\n",
    "    if not is_normally_distributed(baseline):\n",
    "        print(\"Warning: baseline is not normally distributed!\")\n",
    "        # print(\"Therefore, we do a Wilcoxon signed-rank test instead of a Student's t-test!\")\n",
    "        # test_statistic, p_value = wilcoxon(sample.array - population_mean, alternative=alternative)\n",
    "        # return test_statistic, p_value\n",
    "\n",
    "    test_statistic, p_value = ttest_ind(\n",
    "        sample.array, baseline.array, equal_var=equal_var, alternative=alternative\n",
    "    )\n",
    "    return test_statistic, p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.354540175Z",
     "start_time": "2023-11-01T14:01:13.338215333Z"
    }
   },
   "id": "1eaaa267aedff3ba"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def interpret_p_value(\n",
    "    p_value: float,\n",
    "    # alternative: str,\n",
    "    alpha: float = ALPHA,\n",
    ") -> str:\n",
    "    if p_value < alpha:\n",
    "        return \"Reject H0\"\n",
    "    else:\n",
    "        return \"Cannot reject H0\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.366500250Z",
     "start_time": "2023-11-01T14:01:13.352442448Z"
    }
   },
   "id": "46ab88ffb3d0f902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example Usage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "279ffc159089ec11"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test example\n",
      "Sample is normally distributed: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapiro-Wilk test example\")\n",
    "sample = Sample([2.5, 3.1, 2.8, 3.4, 2.9, 3.0, 3.3, 2.6, 3.2, 3.1])\n",
    "result = is_normally_distributed(sample)\n",
    "print(f\"Sample is normally distributed: {result}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.382045508Z",
     "start_time": "2023-11-01T14:01:13.366411832Z"
    }
   },
   "id": "fbf7881d94b693a0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample t-test example\n",
      "Sample: [10. 11. 12. 13. 14.])\n",
      "Population mean: 14.0\n",
      "Alternative: two-sided, t-statistic: -2.828, p-value: 0.047, Reject H0 (p<0.05): True\n",
      "Alternative: less     , t-statistic: -2.828, p-value: 0.024, Reject H0 (p<0.05): True\n",
      "Alternative: greater  , t-statistic: -2.828, p-value: 0.976, Reject H0 (p<0.05): False\n",
      "\n",
      "Two sample t-test example\n",
      "Sample: [10. 11. 12.])\n",
      "Baseline: [12. 13. 14.])\n",
      "Alternative: two-sided, t-statistic: -2.449, p-value: 0.070, Reject H0 (p<0.05): False\n",
      "Alternative: less     , t-statistic: -2.449, p-value: 0.035, Reject H0 (p<0.05): True\n",
      "Alternative: greater  , t-statistic: -2.449, p-value: 0.965, Reject H0 (p<0.05): False\n"
     ]
    }
   ],
   "source": [
    "print(\"One sample t-test example\")\n",
    "sample = Sample([10.0, 11.0, 12.0, 13.0, 14.0])\n",
    "population_mean = 14.0\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Population mean: {population_mean}\")\n",
    "for alternative in ALTERNATIVES:\n",
    "    t_stat, p_val = one_sample_t_test(sample, population_mean, alternative)\n",
    "    print(\n",
    "        f\"Alternative: {alternative:9s}, \"\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTwo sample t-test example\")\n",
    "sample = Sample(np.array([10.0, 11.0, 12.0]))\n",
    "baseline = Sample(np.array([12.0, 13.0, 14.0]))\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Baseline: {baseline}\")\n",
    "for alternative in ALTERNATIVES:\n",
    "    t_stat, p_val = two_sample_t_test(sample, baseline, alternative)\n",
    "    print(\n",
    "        f\"Alternative: {alternative:9s}, \"\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.424890441Z",
     "start_time": "2023-11-01T14:01:13.379551185Z"
    }
   },
   "id": "84baad5a7392d8a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments\n",
    "\n",
    "## Tokenizers\n",
    "\n",
    "### Guacamol/SMILES\n",
    "\n",
    "#### The initial \"best\" tokenizer\n",
    "\n",
    "This is based on a single run for each tokenizer.\n",
    "A single run consists of:\n",
    "\n",
    "- a training with fixed seed\n",
    "- a generation with fixed seed\n",
    "- FCD as the metric \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fb8d2d2b2f7ebb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Statistical tests for the \"best\" tokenizer\n",
    "\n",
    "This is based on 5 runs for the \"best\" tokenizer.\n",
    "The 5 runs are:\n",
    "\n",
    "- a training with random seed\n",
    "- a generation with fixed seed\n",
    "- FCD as the metric\n",
    "\n",
    "At this point we have 5 FCD values for the \"best\" tokenizer.\n",
    "We then do a one-sample t-test and compare the sample with the \"next best\" tokenizer. If the current \"best\" tokenizer can be considered \"done\" and we declare the \"best\" tokenizer as the \"winner\". If not, we repeat the process with the \"next best\" tokenizer and perform a two-sample t-test. We repeat this process until we have a winner, or, we conculude that we have a couple of tokenizers which seem to perform equally well.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21c7f589001ae7dc"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best tokenizer char_wordpiece_176 has a mean of 0.2192 and a std.dev. of 0.0060\n",
      "Compare with single FCD value of other tokenizers (descending by FCD)\n",
      "Perform statistical test, (alternative: less)\n",
      "\n",
      "char_wordpiece_88   : 0.2426\n",
      "t-statistic: -8.677, p-value: 0.000, Reject H0 (p<0.05): True\n",
      "\n",
      "smarts_wordlevel_106: 0.2413\n",
      "t-statistic: -8.208, p-value: 0.001, Reject H0 (p<0.05): True\n",
      "\n",
      "atom_wordlevel_50   : 0.2393\n",
      "t-statistic: -7.462, p-value: 0.001, Reject H0 (p<0.05): True\n",
      "\n",
      "char_bpe_44         : 0.2358\n",
      "t-statistic: -6.168, p-value: 0.002, Reject H0 (p<0.05): True\n",
      "\n",
      "char_unigram_44     : 0.2296\n",
      "t-statistic: -3.856, p-value: 0.009, Reject H0 (p<0.05): True\n",
      "\n",
      "char_wordlevel_38   : 0.2257\n",
      "t-statistic: -2.430, p-value: 0.036, Reject H0 (p<0.05): True\n",
      "\n",
      "char_bpe_176        : 0.2245\n",
      "t-statistic: -1.959, p-value: 0.061, Reject H0 (p<0.05): False\n",
      "\n",
      "char_bpe_88         : 0.2214\n",
      "t-statistic: -0.815, p-value: 0.230, Reject H0 (p<0.05): False\n",
      "\n",
      "char_unigram_88     : 0.2189\n",
      "t-statistic: 0.088, p-value: 0.533, Reject H0 (p<0.05): False\n"
     ]
    }
   ],
   "source": [
    "guacamol_char_wordpiece_176 = Sample(\n",
    "    [\n",
    "        0.21138082989205031,\n",
    "        0.22424112983600253,\n",
    "        0.22342369151375863,\n",
    "        0.21396691344180852,\n",
    "        0.22290331624026294,\n",
    "    ]\n",
    ")\n",
    "\n",
    "guacamol_others: dict[str, float] = {\n",
    "    \"char_wordlevel_38\": 0.22573631123455584,\n",
    "    \"char_bpe_44\": 0.23582004914318588,\n",
    "    \"char_bpe_88\": 0.22138152297816305,\n",
    "    \"char_bpe_176\": 0.22446600524058624,\n",
    "    \"char_wordpiece_88\": 0.24258628303761043,\n",
    "    \"char_unigram_44\": 0.22958462926293066,\n",
    "    \"char_unigram_88\": 0.2189468387861666,\n",
    "    \"atom_wordlevel_50\": 0.23930838874149174,\n",
    "    \"smarts_wordlevel_106\": 0.24132050338971567,\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Initial best tokenizer char_wordpiece_176 has a mean of {guacamol_char_wordpiece_176.mean:.4f} and a std.dev. of {guacamol_char_wordpiece_176.std:.4f}\"\n",
    ")\n",
    "print(\"Compare with single FCD value of other tokenizers (descending by FCD)\")\n",
    "alternative = \"less\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "\n",
    "for tokenizer, fcd in sorted(guacamol_others.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"\\n{tokenizer:20s}: {fcd:.4f}\")\n",
    "    t_stat, p_val = one_sample_t_test(guacamol_char_wordpiece_176, fcd, alternative)\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:38:14.110381607Z",
     "start_time": "2023-11-01T14:38:14.098879563Z"
    }
   },
   "id": "3c9ca98f81096f3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results for the initial \"best\" tokenizer\n",
    "\n",
    "The initial \"best\" tokenizer is char_wordpiece_176. After 5 runs and 5 FCD values we see, that the mean of those 5 values is worse than the single char_unigram_88 value. Therefore, we can expect that the char_wordpiece_176 tokenizer is not better than char_unigram_88. Also, its better value is not statistically significant comparing it to char_bpe_88 and char_bpe_176.\n",
    "\n",
    "We move on with getting 5 FCD values of the 2nd best tokenizer, i.e. char_unigram_88 and performing a two-sample t-test of char_unigram_88 and char_wordpiece_176.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3c96da0a6378d19"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "guacamol_char_unigram_88 = Sample(\n",
    "    [\n",
    "        0.21138082989205031,\n",
    "        0.22424112983600253,\n",
    "        0.22342369151375863,\n",
    "        0.21396691344180852,\n",
    "        0.22290331624026294,\n",
    "    ]\n",
    ")\n",
    "\n",
    "guacamol_others: dict[str, float] = {\n",
    "    \"char_wordlevel_38\": 0.22573631123455584,\n",
    "    \"char_bpe_44\": 0.23582004914318588,\n",
    "    \"char_bpe_88\": 0.22138152297816305,\n",
    "    \"char_bpe_176\": 0.22446600524058624,\n",
    "    \"char_wordpiece_88\": 0.24258628303761043,\n",
    "    \"char_unigram_44\": 0.22958462926293066,\n",
    "    \"atom_wordlevel_50\": 0.23930838874149174,\n",
    "    \"smarts_wordlevel_106\": 0.24132050338971567,\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Initial 2nd best tokenizer char_unigram_88 has a mean of {guacamol_char_unigram_88.mean:.4f} and a std.dev. of {guacamol_char_unigram_88.std:.4f}\"\n",
    ")\n",
    "print(\"Compare with sample of initial best tokenizer (char_wordpiece_176)\")\n",
    "alternative = \"less\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "t_stat, p_val = two_sample_t_test(\n",
    "    guacamol_char_unigram_88, guacamol_char_wordpiece_176, alternative\n",
    ")\n",
    "print(\n",
    "    f\"t-statistic: {t_stat:.3f}, \"\n",
    "    f\"p-value: {p_val:.3f}, \"\n",
    "    f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Compare with single FCD value of other tokenizers (descending by FCD)\")\n",
    "alternative = \"less\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "\n",
    "for tokenizer, fcd in sorted(guacamol_others.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"\\n{tokenizer:20s}: {fcd:.4f}\")\n",
    "    t_stat, p_val = one_sample_t_test(guacamol_char_wordpiece_176, fcd, alternative)\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.425042587Z",
     "start_time": "2023-11-01T14:01:13.424607734Z"
    }
   },
   "id": "225a73d0bbc30fa3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### USPTO50K/SMARTS\n",
    "\n",
    "#### The initial \"best\" tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bf7d52f64c2aa0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Statistical tests for the \"best\" tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cac201e60eb05b8a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 2.688, p-value: 0.027\n",
      "Reject H0\n"
     ]
    }
   ],
   "source": [
    "atom_smarts_947_fcd = Sample(\n",
    "    [\n",
    "        711.0,\n",
    "        712.0,\n",
    "        708.0,\n",
    "        738.0,\n",
    "        688.0,\n",
    "    ]\n",
    ")\n",
    "# TODO Check this number, not correct!\n",
    "char_unigram_88_fcd = 690\n",
    "\n",
    "t_stat, p_val = one_sample_t_test(\n",
    "    atom_smarts_947_fcd, char_unigram_88_fcd, alternative=\"greater\"\n",
    ")\n",
    "print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n",
    "print(interpret_p_value(p_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.425545832Z",
     "start_time": "2023-11-01T14:01:13.424770273Z"
    }
   },
   "id": "3e72f58d4d3cff8c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T14:01:13.425874993Z",
     "start_time": "2023-11-01T14:01:13.424982061Z"
    }
   },
   "id": "d0bebbd7f3869b5c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
