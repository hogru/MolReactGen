{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Prepare the statistical tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95a6405014065f5e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_1samp, ttest_ind  # t"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.262941280Z",
     "start_time": "2023-11-06T14:15:54.057515915Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "ALTERNATIVES = (\"two-sided\", \"less\", \"greater\")\n",
    "ALPHA = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.341941891Z",
     "start_time": "2023-11-06T14:15:54.073263916Z"
    }
   },
   "id": "444ab0135c733968"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Sample:\n",
    "    values: Sequence[float]\n",
    "    array: np.ndarray = None\n",
    "    ddof: int = 1\n",
    "    mean: float = None\n",
    "    std: float = None\n",
    "    variance: float = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.array = np.array(self.values)\n",
    "        self.mean, self.std, self.var = self.get_basic_stats()\n",
    "\n",
    "    def get_basic_stats(self) -> tuple[float, float, float]:\n",
    "        mean = np.mean(self.array)\n",
    "        std = np.std(self.array, ddof=self.ddof)\n",
    "        var = np.var(self.array, ddof=self.ddof)\n",
    "        return mean, std, var\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.array)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Sample({self.values}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.array})\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.385680338Z",
     "start_time": "2023-11-06T14:15:54.083057307Z"
    }
   },
   "id": "2e1f4a4d72352cdf"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# This was/is only a test whether my two_sample_t_test function works (it does)\n",
    "def compare_two_samples(s1: Sample, s2: Sample) -> tuple[float, float]:\n",
    "    t_stat, p_value = ttest_ind(s1.array, s2.array)  # just to check; fake!\n",
    "    return t_stat, p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.392327714Z",
     "start_time": "2023-11-06T14:15:54.093225578Z"
    }
   },
   "id": "27019476b7749854"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Same calculation for both one and two sample t-tests\n",
    "def _calculate_p_value(t_statistic: float, df: int, alternative: str) -> float:\n",
    "    alternative = alternative.strip().lower()\n",
    "    if alternative == \"two_sided\":\n",
    "        p_value = (1 - t.cdf(abs(t_statistic), df)) * 2.0\n",
    "    elif alternative == \"less\":\n",
    "        p_value = t.cdf(t_statistic, df)\n",
    "    elif alternative == \"greater\":\n",
    "        p_value = 1 - t.cdf(t_statistic, df)\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be 'two_sided', 'greater' or 'smaller'\")\n",
    "\n",
    "    return p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.395421976Z",
     "start_time": "2023-11-06T14:15:54.130206851Z"
    }
   },
   "id": "68200c14b46ccc24"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def is_normally_distributed(sample: Sample, alpha: float = ALPHA):\n",
    "    _, p_value = shapiro(sample.array)\n",
    "    return p_value > alpha"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.506009524Z",
     "start_time": "2023-11-06T14:15:54.130330839Z"
    }
   },
   "id": "c0d4cdc77bbde306"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def one_sample_t_test(\n",
    "    sample: Sample, population_mean: float, alternative: str = \"two_sided\"\n",
    ") -> tuple[float, float]:\n",
    "    # n = len(sample)\n",
    "    # df = n - 1\n",
    "    # t_statistic = (sample.mean - population_mean) / (sample.std / np.sqrt(n))\n",
    "    # p_value = _calculate_p_value(t_statistic, df, alternative)\n",
    "\n",
    "    if not is_normally_distributed(sample):\n",
    "        print(\"Warning: sample is not normally distributed!\")\n",
    "        # print(\"Therefore, we do a Wilcoxon signed-rank test instead of a Student's t-test!\")\n",
    "        # test_statistic, p_value = wilcoxon(sample.array - population_mean, alternative=alternative)\n",
    "        # return test_statistic, p_value\n",
    "    test_statistic, p_value = ttest_1samp(\n",
    "        sample.array, population_mean, alternative=alternative\n",
    "    )\n",
    "    return test_statistic, p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.506634123Z",
     "start_time": "2023-11-06T14:15:54.172808564Z"
    }
   },
   "id": "d2ce292f1d0d6014"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def two_sample_t_test(\n",
    "    sample: Sample, baseline: Sample, alternative: str = \"different\"\n",
    ") -> tuple[float, float]:\n",
    "    # n1 = len(sample)\n",
    "    # n2 = len(baseline)\n",
    "    if sample.std > 2.0 * baseline.std or baseline.std > 2.0 * sample.std:\n",
    "        print(\"Warning: standard deviations differ by more than a factor of 2\")\n",
    "        print(\"Therefore, we do a Welch's t-test instead of a Student's t-test!\")\n",
    "        equal_var = False\n",
    "    else:\n",
    "        equal_var = True\n",
    "\n",
    "    # pooled_std = np.sqrt(((n1 - 1) * sample.std ** 2 + (n2 - 1) * baseline.std ** 2) / (n1 + n2 - 2))\n",
    "    # t_statistic = (sample.mean - baseline.mean) / (pooled_std * np.sqrt(1 / n1 + 1 / n2))\n",
    "    # df = n1 + n2 - 2\n",
    "    # p_value = _calculate_p_value(t_statistic, df, alternative)\n",
    "\n",
    "    if not is_normally_distributed(sample):\n",
    "        print(\"Warning: sample is not normally distributed!\")\n",
    "        # print(\"Therefore, we do a Wilcoxon signed-rank test instead of a Student's t-test!\")\n",
    "        # test_statistic, p_value = wilcoxon(sample.array - population_mean, alternative=alternative)\n",
    "        # return test_statistic, p_value\n",
    "    if not is_normally_distributed(baseline):\n",
    "        print(\"Warning: baseline is not normally distributed!\")\n",
    "        # print(\"Therefore, we do a Wilcoxon signed-rank test instead of a Student's t-test!\")\n",
    "        # test_statistic, p_value = wilcoxon(sample.array - population_mean, alternative=alternative)\n",
    "        # return test_statistic, p_value\n",
    "\n",
    "    test_statistic, p_value = ttest_ind(\n",
    "        sample.array, baseline.array, equal_var=equal_var, alternative=alternative\n",
    "    )\n",
    "    return test_statistic, p_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.506793324Z",
     "start_time": "2023-11-06T14:15:54.173032347Z"
    }
   },
   "id": "1eaaa267aedff3ba"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def interpret_p_value(\n",
    "    p_value: float,\n",
    "    # alternative: str,\n",
    "    alpha: float = ALPHA,\n",
    ") -> str:\n",
    "    if p_value < alpha:\n",
    "        return \"Reject H0\"\n",
    "    else:\n",
    "        return \"Cannot reject H0\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.506912600Z",
     "start_time": "2023-11-06T14:15:54.173103452Z"
    }
   },
   "id": "46ab88ffb3d0f902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example Usage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "279ffc159089ec11"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test example\n",
      "Sample is normally distributed: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapiro-Wilk test example\")\n",
    "sample = Sample([2.5, 3.1, 2.8, 3.4, 2.9, 3.0, 3.3, 2.6, 3.2, 3.1])\n",
    "result = is_normally_distributed(sample)\n",
    "print(f\"Sample is normally distributed: {result}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.509750950Z",
     "start_time": "2023-11-06T14:15:54.189196061Z"
    }
   },
   "id": "fbf7881d94b693a0"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample t-test example\n",
      "Sample: [10. 11. 12. 13. 14.])\n",
      "Population mean: 14.0\n",
      "Alternative: two-sided, t-statistic: -2.828, p-value: 0.047, Reject H0 (p<0.05): True\n",
      "Alternative: less     , t-statistic: -2.828, p-value: 0.024, Reject H0 (p<0.05): True\n",
      "Alternative: greater  , t-statistic: -2.828, p-value: 0.976, Reject H0 (p<0.05): False\n",
      "\n",
      "Two sample t-test example\n",
      "Sample: [10. 11. 12.])\n",
      "Baseline: [12. 13. 14.])\n",
      "Alternative: two-sided, t-statistic: -2.449, p-value: 0.070, Reject H0 (p<0.05): False\n",
      "Alternative: less     , t-statistic: -2.449, p-value: 0.035, Reject H0 (p<0.05): True\n",
      "Alternative: greater  , t-statistic: -2.449, p-value: 0.965, Reject H0 (p<0.05): False\n"
     ]
    }
   ],
   "source": [
    "print(\"One sample t-test example\")\n",
    "sample = Sample([10.0, 11.0, 12.0, 13.0, 14.0])\n",
    "population_mean = 14.0\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Population mean: {population_mean}\")\n",
    "for alternative in ALTERNATIVES:\n",
    "    t_stat, p_val = one_sample_t_test(sample, population_mean, alternative)\n",
    "    print(\n",
    "        f\"Alternative: {alternative:9s}, \"\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTwo sample t-test example\")\n",
    "sample = Sample(np.array([10.0, 11.0, 12.0]))\n",
    "baseline = Sample(np.array([12.0, 13.0, 14.0]))\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Baseline: {baseline}\")\n",
    "for alternative in ALTERNATIVES:\n",
    "    t_stat, p_val = two_sample_t_test(sample, baseline, alternative)\n",
    "    print(\n",
    "        f\"Alternative: {alternative:9s}, \"\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.516732259Z",
     "start_time": "2023-11-06T14:15:54.205304078Z"
    }
   },
   "id": "84baad5a7392d8a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments\n",
    "\n",
    "## Tokenizers\n",
    "\n",
    "### Guacamol/SMILES\n",
    "\n",
    "#### The initial \"best\" tokenizer\n",
    "\n",
    "This is based on a single run for each tokenizer.\n",
    "A single run consists of:\n",
    "\n",
    "- a training with fixed seed\n",
    "- a generation with fixed seed\n",
    "- FCD as the metric \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fb8d2d2b2f7ebb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Statistical tests for the \"best\" tokenizer\n",
    "\n",
    "This is based on 5 runs for the \"best\" tokenizer.\n",
    "The 5 runs are:\n",
    "\n",
    "- a training with random seed\n",
    "- a generation with fixed seed\n",
    "- FCD as the metric\n",
    "\n",
    "At this point we have 5 FCD values for the \"best\" tokenizer.\n",
    "We then do a one-sample t-test and compare the sample with the \"next best\" tokenizer. If the current \"best\" tokenizer can be considered \"done\" and we declare the \"best\" tokenizer as the \"winner\". If not, we repeat the process with the \"next best\" tokenizer and perform a two-sample t-test. We repeat this process until we have a winner, or, we conculude that we have a couple of tokenizers which seem to perform equally well.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21c7f589001ae7dc"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best tokenizer char_wordpiece_176 has a mean of 0.2192 and a std.dev. of 0.0060\n",
      "\n",
      "Compare with single FCD value of other tokenizers (descending by FCD)\n",
      "Perform statistical test... (alternative: less)\n",
      "\n",
      "char_wordpiece_88   : 0.2426\n",
      "t-statistic: -8.677, p-value: 0.000, Reject H0 (p<0.05): True\n",
      "\n",
      "smarts_wordlevel_106: 0.2413\n",
      "t-statistic: -8.208, p-value: 0.001, Reject H0 (p<0.05): True\n",
      "\n",
      "atom_wordlevel_50   : 0.2393\n",
      "t-statistic: -7.462, p-value: 0.001, Reject H0 (p<0.05): True\n",
      "\n",
      "char_bpe_44         : 0.2358\n",
      "t-statistic: -6.168, p-value: 0.002, Reject H0 (p<0.05): True\n",
      "\n",
      "char_unigram_44     : 0.2296\n",
      "t-statistic: -3.856, p-value: 0.009, Reject H0 (p<0.05): True\n",
      "\n",
      "char_wordlevel_38   : 0.2257\n",
      "t-statistic: -2.430, p-value: 0.036, Reject H0 (p<0.05): True\n",
      "\n",
      "char_bpe_176        : 0.2245\n",
      "t-statistic: -1.959, p-value: 0.061, Reject H0 (p<0.05): False\n",
      "\n",
      "char_bpe_88         : 0.2214\n",
      "t-statistic: -0.815, p-value: 0.230, Reject H0 (p<0.05): False\n",
      "\n",
      "char_unigram_88     : 0.2189\n",
      "t-statistic: 0.088, p-value: 0.533, Reject H0 (p<0.05): False\n"
     ]
    }
   ],
   "source": [
    "guacamol_char_wordpiece_176 = Sample(\n",
    "    [\n",
    "        0.21138082989205031,\n",
    "        0.22424112983600253,\n",
    "        0.22342369151375863,\n",
    "        0.21396691344180852,\n",
    "        0.22290331624026294,\n",
    "    ]\n",
    ")\n",
    "\n",
    "guacamol_others: dict[str, float] = {\n",
    "    \"char_wordlevel_38\": 0.22573631123455584,\n",
    "    \"char_bpe_44\": 0.23582004914318588,\n",
    "    \"char_bpe_88\": 0.22138152297816305,\n",
    "    \"char_bpe_176\": 0.22446600524058624,\n",
    "    \"char_wordpiece_88\": 0.24258628303761043,\n",
    "    \"char_unigram_44\": 0.22958462926293066,\n",
    "    \"char_unigram_88\": 0.2189468387861666,\n",
    "    \"atom_wordlevel_50\": 0.23930838874149174,\n",
    "    \"smarts_wordlevel_106\": 0.24132050338971567,\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Initial best tokenizer char_wordpiece_176 has a mean of {guacamol_char_wordpiece_176.mean:.4f} and a std.dev. of {guacamol_char_wordpiece_176.std:.4f}\"\n",
    ")\n",
    "print(\"\\nCompare with single FCD value of other tokenizers (descending by FCD)\")\n",
    "alternative = \"less\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "\n",
    "for tokenizer, fcd in sorted(guacamol_others.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"\\n{tokenizer:20s}: {fcd:.4f}\")\n",
    "    t_stat, p_val = one_sample_t_test(guacamol_char_wordpiece_176, fcd, alternative)\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.517223307Z",
     "start_time": "2023-11-06T14:15:54.248740110Z"
    }
   },
   "id": "3c9ca98f81096f3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results for the initial \"best\" tokenizer\n",
    "\n",
    "The initial \"best\" tokenizer is char_wordpiece_176. After 5 runs and 5 FCD values we see, that the mean of those 5 values is worse than the single char_unigram_88 value. Therefore, we can expect that the char_wordpiece_176 tokenizer is not better than char_unigram_88. Also, its better value is not statistically significant comparing it to char_bpe_88 and char_bpe_176.\n",
    "\n",
    "We move on with getting 5 FCD values of the 2nd best tokenizer, i.e. char_unigram_88 and performing a two-sample t-test of char_unigram_88 and char_wordpiece_176.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3c96da0a6378d19"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 2nd best tokenizer char_unigram_88 has a mean of 0.2224 and a std.dev. of 0.0062\n",
      "\n",
      "Compare with sample of initial best tokenizer (char_wordpiece_176)\n",
      "Perform statistical test... (alternative: less)\n",
      "t-statistic: 0.829, p-value: 0.784, Reject H0 (p<0.05): False\n",
      "\n",
      "Compare with single FCD value of other tokenizers (descending by FCD)\n",
      "Perform statistical test... (alternative: less)\n",
      "\n",
      "char_wordpiece_88   : 0.2426\n",
      "t-statistic: -8.677, p-value: 0.000, Reject H0 (p<0.05): True\n",
      "\n",
      "smarts_wordlevel_106: 0.2413\n",
      "t-statistic: -8.208, p-value: 0.001, Reject H0 (p<0.05): True\n",
      "\n",
      "atom_wordlevel_50   : 0.2393\n",
      "t-statistic: -7.462, p-value: 0.001, Reject H0 (p<0.05): True\n",
      "\n",
      "char_bpe_44         : 0.2358\n",
      "t-statistic: -6.168, p-value: 0.002, Reject H0 (p<0.05): True\n",
      "\n",
      "char_unigram_44     : 0.2296\n",
      "t-statistic: -3.856, p-value: 0.009, Reject H0 (p<0.05): True\n",
      "\n",
      "char_wordlevel_38   : 0.2257\n",
      "t-statistic: -2.430, p-value: 0.036, Reject H0 (p<0.05): True\n",
      "\n",
      "char_bpe_176        : 0.2245\n",
      "t-statistic: -1.959, p-value: 0.061, Reject H0 (p<0.05): False\n",
      "\n",
      "char_bpe_88         : 0.2214\n",
      "t-statistic: -0.815, p-value: 0.230, Reject H0 (p<0.05): False\n"
     ]
    }
   ],
   "source": [
    "guacamol_char_unigram_88 = Sample(\n",
    "    [\n",
    "        0.22215763836744884,\n",
    "        0.21625658903371914,\n",
    "        0.21653028109176375,\n",
    "        0.22646688628489642,\n",
    "        0.23060648678460893,\n",
    "    ]\n",
    ")\n",
    "\n",
    "guacamol_others: dict[str, float] = {\n",
    "    \"char_wordlevel_38\": 0.22573631123455584,\n",
    "    \"char_bpe_44\": 0.23582004914318588,\n",
    "    \"char_bpe_88\": 0.22138152297816305,\n",
    "    \"char_bpe_176\": 0.22446600524058624,\n",
    "    \"char_wordpiece_88\": 0.24258628303761043,\n",
    "    \"char_unigram_44\": 0.22958462926293066,\n",
    "    \"atom_wordlevel_50\": 0.23930838874149174,\n",
    "    \"smarts_wordlevel_106\": 0.24132050338971567,\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Initial 2nd best tokenizer char_unigram_88 has a mean of {guacamol_char_unigram_88.mean:.4f} and a std.dev. of {guacamol_char_unigram_88.std:.4f}\"\n",
    ")\n",
    "print(\"\\nCompare with sample of initial best tokenizer (char_wordpiece_176)\")\n",
    "alternative = \"less\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "t_stat, p_val = two_sample_t_test(\n",
    "    guacamol_char_unigram_88, guacamol_char_wordpiece_176, alternative\n",
    ")\n",
    "print(\n",
    "    f\"t-statistic: {t_stat:.3f}, \"\n",
    "    f\"p-value: {p_val:.3f}, \"\n",
    "    f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nCompare with single FCD value of other tokenizers (descending by FCD)\")\n",
    "alternative = \"less\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "\n",
    "for tokenizer, fcd in sorted(guacamol_others.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"\\n{tokenizer:20s}: {fcd:.4f}\")\n",
    "    t_stat, p_val = one_sample_t_test(guacamol_char_wordpiece_176, fcd, alternative)\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.536707663Z",
     "start_time": "2023-11-06T14:15:54.293026475Z"
    }
   },
   "id": "225a73d0bbc30fa3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results for the 2nd “best” tokenizer\n",
    "\n",
    "After getting 5 FCD values of the 2nd best tokenizer, i.e. char_unigram_88 and performing a two-sample t-test of char_unigram_88 and char_wordpiece_176 we can not rejct H0, i.e. the two tokenizers are not statistically different. Therefore, we can conclude that we have a couple of tokenizers which seem to perform equally well.\n",
    "\n",
    "For the comparison with GuacaMol we select the model with a char_wordpiece_176 tokenizer with the lowest FCD value. The model directory is checkpoints/guacamol/tokenizers/char_wordpiece_176/2023-10-31_05-26-52_experiment.\n",
    "\n",
    "We generate 5 samples of 10,000 molecules, this time with a random seed for each sample. We then calculate the FCD for each sample and compare the 5 samples with the value of GuacaMol with a single-sample one-sided t-test."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66c8173859bc09a5"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected tokenizer char_wordpiece_176 has a mean of 0.2252 and a std.dev. of 0.0073\n",
      "\n",
      "Compare with single FCD value of GuacaMol paper\n",
      "Perform statistical test... (alternative: less)\n",
      "t-statistic: -70.491, p-value: 0.000, Reject H0 (p<0.05): True\n"
     ]
    }
   ],
   "source": [
    "guacamol_char_wordpiece_176 = Sample(\n",
    "    [\n",
    "        0.2286251555231189,\n",
    "        0.23513992637839465,\n",
    "        0.21683749015160458,\n",
    "        0.2195920751401701,\n",
    "        0.22596241125135919,\n",
    "    ]\n",
    ")\n",
    "\n",
    "guacamol_original = 0.455  # TODO replace with correct value\n",
    "\n",
    "print(\n",
    "    f\"Selected tokenizer char_wordpiece_176 has a mean of {guacamol_char_wordpiece_176.mean:.4f} and a std.dev. of {guacamol_char_wordpiece_176.std:.4f}\"\n",
    ")\n",
    "print(\"\\nCompare with single FCD value of GuacaMol paper\")\n",
    "alternative = \"less\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "\n",
    "t_stat, p_val = one_sample_t_test(\n",
    "    guacamol_char_wordpiece_176, guacamol_original, alternative\n",
    ")\n",
    "print(\n",
    "    f\"t-statistic: {t_stat:.3f}, \"\n",
    "    f\"p-value: {p_val:.3f}, \"\n",
    "    f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.538143829Z",
     "start_time": "2023-11-06T14:15:54.293268602Z"
    }
   },
   "id": "2e97a46124536579"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other metrics of char_wordpiece_176:\n",
      "Other metrics of char_wordpiece_176:\n",
      "Metric: validity     Mean: 0.976   Std.dev. 0.002\n",
      "Metric: uniqueness   Mean: 0.999   Std.dev. 0.000\n",
      "Metric: novelty      Mean: 0.935   Std.dev. 0.002\n",
      "Metric: fcd_g_mols   Mean: 0.956   Std.dev. 0.001\n"
     ]
    }
   ],
   "source": [
    "# We then calculate mean and sigma of the other metrics\n",
    "\n",
    "validity = Sample(\n",
    "    [\n",
    "        0.9779,\n",
    "        0.9773,\n",
    "        0.9753,\n",
    "        0.9731,\n",
    "        0.976,\n",
    "    ]\n",
    ")\n",
    "\n",
    "uniqueness = Sample(\n",
    "    [\n",
    "        0.9989774005522037,\n",
    "        0.9995907090964903,\n",
    "        0.9994873372295704,\n",
    "        0.9993834138320831,\n",
    "        0.9995901639344262,\n",
    "    ]\n",
    ")\n",
    "\n",
    "novelty = Sample(\n",
    "    [\n",
    "        0.9317227966014945,\n",
    "        0.9375575801003173,\n",
    "        0.9344480919162905,\n",
    "        0.9374807197943444,\n",
    "        0.9353218532185322,\n",
    "    ]\n",
    ")\n",
    "\n",
    "fcd_g_mols = Sample(\n",
    "    [\n",
    "        0.955304605131761,\n",
    "        0.9540606975651333,\n",
    "        0.9575594241953026,\n",
    "        0.9570320337197208,\n",
    "        0.9558134869949808,\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Other metrics of char_wordpiece_176:\")\n",
    "metrics: dict[str, Sample] = {\n",
    "    \"validity\": validity,\n",
    "    \"uniqueness\": uniqueness,\n",
    "    \"novelty\": novelty,\n",
    "    \"fcd_g_mols\": fcd_g_mols,\n",
    "}\n",
    "\n",
    "print(\"Other metrics of char_wordpiece_176:\")\n",
    "for name, sample in metrics.items():\n",
    "    print(f\"Metric: {name:12s} Mean: {sample.mean:.3f}   Std.dev. {sample.std:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:15:54.539031814Z",
     "start_time": "2023-11-06T14:15:54.293466362Z"
    }
   },
   "id": "8dc88b116213c6e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### USPTO50K/SMARTS\n",
    "\n",
    "#### The initial \"best\" tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bf7d52f64c2aa0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Statistical tests for the \"best\" tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cac201e60eb05b8a"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial best tokenizer char_wordlevel_47 has a mean of 703.2 and a std.dev. of 4.0\n",
      "\n",
      "Compare with single 'known' value of other tokenizers (descending by 'known')\n",
      "Perform statistical test... (alternative: greater)\n",
      "\n",
      "char_bpe_176        : 700.0000\n",
      "t-statistic: 1.806, p-value: 0.073, Reject H0 (p<0.05): False\n",
      "\n",
      "char_wordpiece_94   : 700.0000\n",
      "t-statistic: 1.806, p-value: 0.073, Reject H0 (p<0.05): False\n",
      "\n",
      "char_wordpiece_176  : 700.0000\n",
      "t-statistic: 1.806, p-value: 0.073, Reject H0 (p<0.05): False\n",
      "\n",
      "char_unigram_88     : 700.0000\n",
      "t-statistic: 1.806, p-value: 0.073, Reject H0 (p<0.05): False\n",
      "\n",
      "char_unigram_176    : 700.0000\n",
      "t-statistic: 1.806, p-value: 0.073, Reject H0 (p<0.05): False\n",
      "\n",
      "atom_wordlevel_86   : 700.0000\n",
      "t-statistic: 1.806, p-value: 0.073, Reject H0 (p<0.05): False\n",
      "\n",
      "smarts_wordlevel_947: 700.0000\n",
      "t-statistic: 1.806, p-value: 0.073, Reject H0 (p<0.05): False\n",
      "\n",
      "char_bpe_88         : 701.0000\n",
      "t-statistic: 1.242, p-value: 0.141, Reject H0 (p<0.05): False\n",
      "\n",
      "char_bpe_47         : 702.0000\n",
      "t-statistic: 0.677, p-value: 0.268, Reject H0 (p<0.05): False\n"
     ]
    }
   ],
   "source": [
    "uspto50k_char_wordlevel_47 = Sample(\n",
    "    [\n",
    "        728.0,\n",
    "        701.0,\n",
    "        702.0,\n",
    "        703.0,\n",
    "        710.0,\n",
    "    ]\n",
    ")\n",
    "\n",
    "uspto50k_others: dict[str, float] = {\n",
    "    \"char_bpe_47\": 721.0,\n",
    "    \"char_bpe_88\": 696.0,\n",
    "    \"char_bpe_176\": 618.0,\n",
    "    \"char_wordpiece_94\": 587.0,\n",
    "    \"char_wordpiece_176\": 557.0,\n",
    "    \"char_unigram_88\": 621.0,\n",
    "    \"char_unigram_176\": 616.0,\n",
    "    \"atom_wordlevel_86\": 729.0,\n",
    "    \"smarts_wordlevel_947\": 735.0,\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Initial best tokenizer char_wordlevel_47 has a mean of {uspto50k_char_wordlevel_47.mean:.1f} and a std.dev. of {uspto50k_char_wordlevel_47.std:.1f}\"\n",
    ")\n",
    "print(\"\\nCompare with single 'known' value of other tokenizers (descending by 'known')\")\n",
    "alternative = \"greater\"\n",
    "print(f\"Perform statistical test... (alternative: {alternative})\")\n",
    "\n",
    "for tokenizer, known in sorted(\n",
    "    uspto50k_others.items(), key=lambda x: x[1], reverse=False\n",
    "):\n",
    "    print(f\"\\n{tokenizer:20s}: {known:.4f}\")\n",
    "    t_stat, p_val = one_sample_t_test(uspto50k_char_wordlevel_47, known, alternative)\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat:.3f}, \"\n",
    "        f\"p-value: {p_val:.3f}, \"\n",
    "        f\"Reject H0 (p<0.05): {p_val < 0.05}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T14:19:12.648996553Z",
     "start_time": "2023-11-06T14:19:12.570315640Z"
    }
   },
   "id": "3e72f58d4d3cff8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-06T14:15:54.658852704Z"
    }
   },
   "id": "d0bebbd7f3869b5c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
